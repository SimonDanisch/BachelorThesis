\section{Introduction}
This Bachelor Thesis is about Romeo, an interactive scripting environment for scientific computing.
Other libraries have been developped to implement Romeo in a modular way, fostering reusability.
The most important library is GLVisulize, which is a generic 3D visualization library for dynamic data. 
The ultimate goal is to make scientific computing more accessible to the user. 

For this, the focus has been put on usability, applied to all the different interfaces, ranging from \ac{API}s to graphical user interfaces. 
The programming language Julia was chosen for implementing all libraries, as it offers a unique combination of speed, high-level programming style and a lot of functionality for scientific computing.

GLVisualize offers a default visualization for every data type. 
It also offers \ac{GUI} elements and editable text fields, which forms the basis for editing scripts and visualizations in Romeo. 
In this way, Romeo offers a primitive form of visual debugging. 
Due to the generic nature of GLVisualize, these interactive features can be used in other programs independant from Romeo.

An introduction to the general field of research and its challenges and problems relevant to this thesis will be extracted.
Finally, this chapter will conclude with a solution to the previously found problems, how to measure the success and give an outlook on the structure of the entire Bachelor Thesis.


\subsection{Scientific Computing}

Scientific computing is computing that evolves around all kind of scientific research.
It is a very broad field involving a lot of different challenges. 
In some areas such as particle physics, most problems are computationally intensive and can only be solved with the help of supercomputers.
In other areas, like robotics, it is important to be efficient because the algorithms are running on embedded systems with limited resources. 
In a other areas, speed is not that important, but it may be that the algorithm itself is very difficult to comprehend. 
The more comprehensible an algorithm can be written in a programming language, the easier it will be to implement the algorithm without errors.
In any case, programming itself is secondary to the researcher.
It can be expected that most researcher only have rudimentary programming skills. 
Even if they are experienced programmers, it is often inefficient to implement complex algorithms, while also dealing with a lot of programming problems.
These problems especially arise, when dealing with low-level programming in order to reach optimal speed.

So things like manual memory management and difficult design patterns with a lot of unnecessary code should be avoided in scientific computing.
This has led to the rise of programming languages and tools specifically tailored to scientific computing.
The most prominent examples include Mathematica, R, and Matlab. 
Python could be in this list as well, but the scientific computing part is only realized by third party libraries, while Python itself is a multi-purpose language.
The others all aim to provide a simple syntax for linear algebra and statistical code while taking away difficult tasks like memory management and multithreading. 
They come with a rich standard library so most research can be done without loading any additional module, which makes them great tools for rapid prototyping.
Currently, these languages suffers from poor performance introduced by the high level of abstraction.
As a consequence, a lot of the performance critical parts are written in another language like C/C++ or Fortran.
This is referred to as the \textbf{The Two Language Problem}\cite{ArrayMultiJeff}.

This leads us straight to the field of research and the problems that are addressed in this thesis.


\subsection{Field of Research and Problem}

In a slow high-level programming language like Matlab, one needs to switch to a fast multi-purpose language, as soon as high-performance is needed.
In this case, one is losing all the advantages of the high-level scientific computing language.
A pattern which has evolved out of this dilemma is to prototype in a nice high-level language and as soon as the algorithm has been confirmed to work, it gets rewritten in a fast language.

This increases development costs and makes it harder to improve the algorithm in the future.

One of the first languages promising to solve this dilemma for scientific computing is Julia\cite{DBLP:journals/corr/BezansonEKS14}. 
It is designed to be high-level and optimized for the work of scientific computing while approaching the speed of statically compiled languages like C.

This thesis is about bringing usability and performance together in the realms of scientific computing and 3D visualization.
These two demands are opposing concepts.
The first is about bringing tasks into a form which is best understandable to humans, and the other is about transforming a task to make it perform well on a specific computer architecture.
These two tasks could not be more different. 
For humans, data and algorithms become understandable if they are high-level and represented visually, auditorial or tactile together with immediate feedback. 
It is the task of making problems accessible to a human, who have evolved capabilities in order to survive and find food and not to create complex algorithms.
Computers, on the other hand, love to have their registers filled optimally, move memory to smaller and faster caches and dislike random access to memory. That is all it cares about, whether a human understands this or not.

To close this gap, compilers have been created. They are translators between human understandable languages to machine instructions.
This is just the first step and many more are needed to create an enjoyable user experience.
These steps range from introducing graphical user interfaces, novel input devices like the mouse, understandable visualizations and so forth.
All these advances have made computers usable for people who have no education in computer science.
Brat Victor writes excellent essays about making programming easier and more understandable to the novel user and is one of the most influential researchers in this field.
He demonstrates, how visualizations, interaction and well chosen abstraction can make programming easier\cite{BretVictorLP}\cite{BretVictorLA}.
The field of scientific computing would profit greatly from integrating Bret Victors ideas due to the complexity and data driven nature of the tasks.

Scientific computing is usually about implementing mathematical equations, complex algorithms and manipulating and analyzing data.
Most research is done in some specialized, high-level scientific computing language\cite{DBLP:journals/corr/abs-1209-5145}.
Barries in this field make it hard for novel users to have a pleasant start.
A few barriers are for example difficult installation processes of specialized software, working on datasets without visualizations and interaction and cumbersome \ac{API}s.
This calls for a visualization library offering interaction and well designed \ac{API}s.
Most state of the art visualization libraries use C++ at their performance critical core, are closed source or they are implemented in a slow language, introducing unavoidable performance bottlenecks.

Using C++ introduces complexity and performance bottlenecks when interfacing with other languages. This is especially true for languages that produce assembly which is not binary compatible to C++. 
The next problem occurs, when the library does not offer the needed functionality and the programmer has to step in and extend the library. 
If it is closed source or one has to switch the language for that, this will either be not possible or introduce additional work.
It is nice to have a library in which one can get results very quickly even though it does not offer high performance. 
But it is very frustrating when one needs to switch to another library for more serious projects, as previously learned concepts and work has to be discarded.
So it is desirable to have a library which scales well from small projects to big projects.

Finally, one often does not have GUI elements. 
Even if there are GUI elements, they might come from a different package (possibly written in yet another language) or they are complicated to use.
All in all, this makes it hard for researchers to visualize and interact with their data and to create solutions which are tailored to the research problem.

\vspace{1em}
\begin{minipage}{\linewidth}
    \centering
    \includegraphics[width=0.7\linewidth]{graphics/surfaces.png}
    \captionof{figure}[Volume Visualization]{different visualizations of $f(x,y,z)=\sin(\frac{x}{15})+\sin(\frac{y}{15})+\sin(\frac{z}{15})$, visualized with Romeo. From left to right: Isosurface with isovalue=0.76, Isosurface with isovalue=0.37, maximum value projection}
    \label{fig:volume}
\end{minipage}
\vspace{1em}

Visualization libraries play an integral role in scientific computing.
As pointed out by Bret Victor, the computer should be used much more to give us insights into algorithms and forming connections between the lines of code and what they actually represent\cite{BretVictorIventingOnPrinciple}.
A good visualization can be the primer to understanding problems better or bringing across novel theories.
Consider the following function: $f(x,y,z)=\sin(\frac{x}{15})+\sin(\frac{y}{15})+\sin(\frac{z}{15})$. 
It describes a 3D volume mathematically. 
This is a simple function, but it is already not that easy to interpret. In Figure \cref{volume} one can see different visualizations of \textit{f}.
If one can interact with this visualization by moving through the iso-values or coloring certain areas, it will make the function more understandable.
This deeper understanding is crucial for identifying problems in the underlying math, extending the function, or explaining it to other people. 
Making problems more understandable opens the gates of scientific computing to novel users.

Also, debugging problems can be easier with a good visualization. 
If one writes an algorithm that calculate normals of faces on a mesh, the errors in the math becomes obvious when visualizing the normals. Without a proper visualization, the output of the algorithm is really hard to comprehend, since its just a huge array of numbers.
Performance bottlenecks in a call-graph can be seen easily if the graph is color-coded for the execution times of a call. 
Making these tasks enjoyable can help to get an easy start in scientific computing.

In summary, the software in this thesis focuses on research which involves writing short scripts while playing around with some parameters and visualizing the results via built-in, or user defined, visualization routines.
An example would be a materials researcher, who is investigating different 3D shapes and materials and their reaction to pressure.
The researcher would need to read in the 3D object they want to analyze, have an easy way to tweak the material parameters and it would be preferable to get instant feedback on how the pressure waves propagate through the object. Also while doing all this, they may want to modify the script that calculates the pressure.
There are quite a few libraries out there offering this. 
The unique benefits of GLVisualize will be discussed in the second chapter.


\subsection{Contribution}

The main contribution of this thesis to field of scientific computing is writing GLVisualize in Julia, which offers the following advantages.

Julia is a high-level language and effort has been put into creating a concise architecture. 
This allows for short development cycles and easyly extendable libraries.

Romeo targets researchers that want to write everything in one language.
As Julia is fast and the library is also written in Julia, this will enable researchers to stay in the same language for their project. 
This makes it easy to create visualization pipelines in which every routine is as fast as it can get. 
On top of that Romeo uses modern \ac{OpenGL}, which allows to achieve fast, hardware accelerated 3D renderings.
Also, the researcher can extend the library in the same language they are already working in. 
In the case of Julia and Romeo, this is especially easy, as every project involved is open source and directly accessible.
This allows for the flexibility and transparency which is needed for big projects.

Another feature that sets GLVisualize appart from other libraries is, that is build for animations from the beginning.

On top of that, the library makes it simple to interact with complex algorithms via widgets and forms a basis for visual debugging. 
This comes with an ease of use, which would be hard to achieve if the library was not that deeply embedded in Julia.


\subsection{Outlook}
This thesis will continue with a chapter \textbf{Background}, which gives the reader an overview over Julia and similar languages with their respective 3D visualization libraries.
After this, the requirements for Romeo will be laid out and how to measure if the requirements were met.
Then the technologies used will be explained, which builds the basis for discussing the implementation.
In the chapter \textbf{Results and Discussion}, one will find if the requirements were met and how Romeo compares to similar software.
This chapter leads straight to the conclusion which will summarize this thesis.
